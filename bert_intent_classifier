{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_intent_classifier","provenance":[{"file_id":"15ive5j2ebUbppY4t7idzXdGZ9mzpJyjT","timestamp":1588512332328},{"file_id":"1J2V1j1bp1OT-vUB3Atc4SFNRgrO8WeY6","timestamp":1586877352219},{"file_id":"1cT6V7UI5l8EVpkqMVblTvMZtJuFq_Tdx","timestamp":1586848980679},{"file_id":"1MFBGvupZd4a9dfSdycY5jRG6u29D4Bs_","timestamp":1586799854434}],"collapsed_sections":[],"mount_file_id":"15JF2My7B0MU3x_wONm8ClT3yR8GHt-eI","authorship_tag":"ABX9TyNMexUlA5/ZzIqjvJZcfnbn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"k8jkdbg7JLMK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595927786292,"user_tz":-480,"elapsed":956,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"0b7eab50-5f6e-4835-e3e5-bdcbacb5ec04"},"source":["\"\"\"\n","參考文章:https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n參考文章:https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html\\n'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"VANYU-BTlzvX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595927789735,"user_tz":-480,"elapsed":4384,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}}},"source":["%%bash\n","pip install transformers tqdm boto3 requests regex -q"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPrn_YzHsMUH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595927799958,"user_tz":-480,"elapsed":14594,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"f1673599-6993-411e-bda8-013bf03d4ca3"},"source":["import torch\n","from transformers import BertModel\n","from transformers import BertTokenizer\n","\n","PRETRAINED_MODEL_NAME = \"hfl/chinese-bert-wwm\" # 指定繁簡中文 BERT-wwm (全詞遮罩) 預訓練模型\n","\n","model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME) # 取得此預訓練模型所使用的 tokenizer\n","\n","print(\"PyTorch 版本:\",torch.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["PyTorch 版本: 1.5.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wQaVQPoRzkai","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595927799960,"user_tz":-480,"elapsed":14582,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"c6da12f1-1455-4698-f9a9-cce65bba7c4e"},"source":["vocab = tokenizer.vocab\n","print(\"字典大小:\",len(vocab))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["字典大小: 21128\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E--4AETaHJRT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"status":"ok","timestamp":1595927799961,"user_tz":-480,"elapsed":14571,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"599e1452-3ed7-4df7-9a47-7921e0e7ad73"},"source":["import random\n","random_tokens = random.sample(list(vocab),10) # sample 10個\n","random_ids = [vocab[t] for t in random_tokens]  #index如何產生??\n","print(\"{0:20}{1:15}\".format(\"token\",\"index\"))\n","print(\"-\" * 25)\n","for t,id in zip(random_tokens,random_ids): #zip:將兩個list包裝成一組\n","    print(\"{0:15}{1:10}\".format(t,id))\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["token               index          \n","-------------------------\n","赣                    6618\n","##刑                 14209\n","##gle               10098\n","##嗯                 14695\n","##ての                12852\n","##轍                 19810\n","嫻                    2078\n","甙                    4492\n","鸟                    7881\n","豇                    6487\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXK_oJYFIeRT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1595927799962,"user_tz":-480,"elapsed":14558,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"f9c007d5-0e20-4777-c4da-f27d4b98d532"},"source":["text = \"[CLS]等到潮水退了，就知道誰沒穿褲子。\"\n","tokens = tokenizer.tokenize(text)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(text)\n","print(tokens)\n","print(ids)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[CLS]等到潮水退了，就知道誰沒穿褲子。\n","['[CLS]', '等', '到', '潮', '水', '退', '了', '，', '就', '知', '道', '誰', '沒', '穿', '褲', '子', '。']\n","[101, 5023, 1168, 4060, 3717, 6842, 749, 8024, 2218, 4761, 6887, 6306, 3760, 4959, 6194, 2094, 511]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CNmJO7oeXXZQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":690},"executionInfo":{"status":"ok","timestamp":1595927800477,"user_tz":-480,"elapsed":15060,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"8dbf7d1c-5d3f-4107-a054-a5515326d630"},"source":["from google.colab import drive\n","import pandas as pd\n","\n","drive.mount('/content/gdrive') # 此處需要登入google帳號\n","# 獲取授權碼之後輸入即可連動雲端硬碟\n","%cd '/content/gdrive/My Drive/Colab Notebooks'\n","\n","# df_train = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/train.csv\")\n","# 取得Dataframe\n","df_train = pd.read_csv('train.csv') # 訓練資料\n","# Dataset is now stored in a Pandas Dataframe\n","\n","print(\"訓練樣本數：\", len(df_train))\n","df_train.head(20)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Colab Notebooks\n","訓練樣本數： 572\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>intent</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>什麼航班資訊確實長榮航空從出發到西雅圖 名古屋</td>\n","      <td>flight_time</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>給我一月 四點的航班和票價從西雅圖到名古屋</td>\n","      <td>flight+airfare</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>什麼航空公司有從西雅圖到名古屋 轉機 早上的 早上的航班</td>\n","      <td>airline</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>該航空公司從西雅圖到名古屋飛</td>\n","      <td>airline</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>告訴我回程 西雅圖和名古屋 之間的票價</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>什麼是西雅圖的最低價的票價名古屋留下一月 四點</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>告訴我最低價的 回程票價從西雅圖到名古屋</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>請找到西雅圖到名古屋的最低價的票價</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>該航空公司從西雅圖飛往名古屋並在大阪停留</td>\n","      <td>airline</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>什麼是西雅圖和名古屋之間的最低價的票價</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>什麼才是從西雅圖到名古屋的最低價的 回程票價</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>您好我能得到一個回程票從西雅圖到名古屋</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>多少轉機航班從去到西雅圖 名古屋 十月 十七號</td>\n","      <td>quantity</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>什麼是最低價的車費，我可以西雅圖和名古屋之間得到</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>什麼是西雅圖到名古屋 頭等艙 回程票價</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>請告訴我航班從西雅圖到名古屋停止大阪航班</td>\n","      <td>airline</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>什麼類型的飛機確實從西雅圖到名古屋 之前 06:00 長榮航空飛</td>\n","      <td>aircraft</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>什麼是從西雅圖到名古屋一個回程飛行最低價的票價</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>什麼是西雅圖的最低價的票價上長榮航空 名古屋</td>\n","      <td>airfare</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>請告訴我航班從西雅圖到名古屋航班</td>\n","      <td>airline</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                text          intent\n","0            什麼航班資訊確實長榮航空從出發到西雅圖 名古屋     flight_time\n","1              給我一月 四點的航班和票價從西雅圖到名古屋  flight+airfare\n","2       什麼航空公司有從西雅圖到名古屋 轉機 早上的 早上的航班         airline\n","3                     該航空公司從西雅圖到名古屋飛         airline\n","4                告訴我回程 西雅圖和名古屋 之間的票價         airfare\n","5            什麼是西雅圖的最低價的票價名古屋留下一月 四點         airfare\n","6               告訴我最低價的 回程票價從西雅圖到名古屋         airfare\n","7                  請找到西雅圖到名古屋的最低價的票價         airfare\n","8               該航空公司從西雅圖飛往名古屋並在大阪停留         airline\n","9                什麼是西雅圖和名古屋之間的最低價的票價         airfare\n","10            什麼才是從西雅圖到名古屋的最低價的 回程票價         airfare\n","11               您好我能得到一個回程票從西雅圖到名古屋         airfare\n","12           多少轉機航班從去到西雅圖 名古屋 十月 十七號        quantity\n","13          什麼是最低價的車費，我可以西雅圖和名古屋之間得到         airfare\n","14               什麼是西雅圖到名古屋 頭等艙 回程票價         airfare\n","15              請告訴我航班從西雅圖到名古屋停止大阪航班         airline\n","16  什麼類型的飛機確實從西雅圖到名古屋 之前 06:00 長榮航空飛        aircraft\n","17           什麼是從西雅圖到名古屋一個回程飛行最低價的票價         airfare\n","18            什麼是西雅圖的最低價的票價上長榮航空 名古屋         airfare\n","19                  請告訴我航班從西雅圖到名古屋航班         airline"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"o5c1RxoaicR5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"status":"ok","timestamp":1595927800479,"user_tz":-480,"elapsed":15049,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"5db4fc45-1525-471a-ea07-42f4565fba45"},"source":["df_train.intent.value_counts() / len(df_train) # 看訓練集每個intent的比例"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["airfare                      0.496503\n","airline                      0.197552\n","flight_time                  0.076923\n","aircraft                     0.061189\n","flight                       0.040210\n","flight+airfare               0.031469\n","quantity                     0.026224\n","city                         0.020979\n","flight_no                    0.017483\n","airport                      0.015734\n","meal                         0.005245\n","airline+flight_no            0.003497\n","cheapest                     0.001748\n","distance                     0.001748\n","aircraft+flight+flight_no    0.001748\n","airfare+flight_time          0.001748\n","Name: intent, dtype: float64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yyu2xvhRcpHF","colab":{"base_uri":"https://localhost:8080/","height":656},"executionInfo":{"status":"ok","timestamp":1595927800480,"user_tz":-480,"elapsed":15034,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"4dd5de37-57cd-4a69-c233-971f6fcb535c"},"source":["# df_test = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/test.csv\")\n","# 取得Dataframe\n","df_test = pd.read_csv('test.csv') # 測試資料\n","# Dataset is now stored in a Pandas Dataframe\n","\n","print(\"訓練樣本數：\", len(df_test))\n","df_test.head(20)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["訓練樣本數： 999\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>intent</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>我想在838分從波士頓飛，並在1110上午在抵達丹佛</td>\n","      <td>飛行時間</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>哪些航班可以從匹茲堡飛往巴爾的摩週四上午</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>什麼是在舊金山的到貨時間為755班機離開華盛頓</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>最廉價的機票從塔科馬到奧蘭多</td>\n","      <td>飛行時間</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>從匹茲堡在1000元往返車費費城</td>\n","      <td>機票</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>我需要一個航班從明天哥倫布明尼阿波利斯</td>\n","      <td>機票</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>什麼樣的飛機是從克利夫蘭到達拉斯的飛行使用</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>告訴我從匹茲堡到洛杉磯週四航班</td>\n","      <td>飛機</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>從波士頓到華盛頓的所有航班</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>什麼樣的地面交通丹佛可用</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>讓我從圣迭戈到紐瓦克的航班由休斯敦方式</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>還有什麼意義在奧蘭多機場</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>什麼是從波士頓到華盛頓國際最便宜的航班</td>\n","      <td>飛機場</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>所有航班巴爾的摩下午6時後</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>給我頭等艙票價從波士頓到丹佛</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>告訴我在丹佛的地面交通</td>\n","      <td>機票</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>我需要的航班信息，週二離開巴爾的摩達拉斯波士頓和波士頓巴爾的摩</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>請給我從波士頓飛往匹茲堡的航班下週的週四</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>我想從丹佛飛往匹茲堡的聯合航空公司</td>\n","      <td>飛行</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>讓我從圣迭戈到紐瓦克的航班</td>\n","      <td>飛行</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               text intent\n","0        我想在838分從波士頓飛，並在1110上午在抵達丹佛   飛行時間\n","1              哪些航班可以從匹茲堡飛往巴爾的摩週四上午     飛行\n","2           什麼是在舊金山的到貨時間為755班機離開華盛頓     飛行\n","3                    最廉價的機票從塔科馬到奧蘭多   飛行時間\n","4                  從匹茲堡在1000元往返車費費城     機票\n","5               我需要一個航班從明天哥倫布明尼阿波利斯     機票\n","6             什麼樣的飛機是從克利夫蘭到達拉斯的飛行使用     飛行\n","7                   告訴我從匹茲堡到洛杉磯週四航班     飛機\n","8                     從波士頓到華盛頓的所有航班     飛行\n","9                      什麼樣的地面交通丹佛可用     飛行\n","10              讓我從圣迭戈到紐瓦克的航班由休斯敦方式     飛行\n","11                     還有什麼意義在奧蘭多機場     飛行\n","12              什麼是從波士頓到華盛頓國際最便宜的航班    飛機場\n","13                    所有航班巴爾的摩下午6時後     飛行\n","14                   給我頭等艙票價從波士頓到丹佛     飛行\n","15                      告訴我在丹佛的地面交通     機票\n","16  我需要的航班信息，週二離開巴爾的摩達拉斯波士頓和波士頓巴爾的摩     飛行\n","17             請給我從波士頓飛往匹茲堡的航班下週的週四     飛行\n","18                我想從丹佛飛往匹茲堡的聯合航空公司     飛行\n","19                    讓我從圣迭戈到紐瓦克的航班     飛行"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"oezIMRidMe8E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595927800482,"user_tz":-480,"elapsed":15022,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"a43d6b9d-e184-4f16-b998-612474eed3a4"},"source":["\"\"\"\n","# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\n","df_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)  #\n","\n","from google.colab import files\n","files.download(\"train.tsv\")\n","\"\"\""],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\\ndf_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)  #\\n\\nfrom google.colab import files\\nfiles.download(\"train.tsv\")\\n'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"fF6LIOFXe-tG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1595927800484,"user_tz":-480,"elapsed":15014,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"50b0f963-8106-46de-ed66-088d68308966"},"source":["\"\"\" \n","此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n","- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n","- segments_tensor：可以用來識別兩個句子界限的 binary tensor \n","- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n","\"\"\"\n","\"\"\"\n","如果輸入只有一個句子就將segments_tensor全部設為0。\n","!!錯誤:segments_tensor = 0 。\n","換成segments_tensor = torch.tensor([0] * length, dtype=torch.long) 就OK了 (edited)\n","\n","參考:https://www.cnblogs.com/d0main/p/10447853.html#%E5%AE%9E%E7%8E%B0\n","\"\"\"\n","from torch.utils.data import Dataset\n","\n","class ATIS_zh_Dataset(Dataset):\n","    # 讀取前處理後的 tsv 檔並初始化一些參數\n","    def __init__(self, mode ,tokenizer):\n","        assert mode in [\"train\" , \"test\"] # 如果mode不等於這兩個，assert Exception\n","        self.mode = mode\n","        self.df = pd.read_csv(mode + \".tsv\" , sep=\"\\t\").fillna(\"\") # 把Na(空值)取代\n","        self.len = len(self.df)\n","        self.intent_map = {\"aircraft\":0,\"aircraft+flight+flight_no\":1,\"airfare\":2,\"airfare+flight_time\":3,\"airline\":4,\"airline+flight_no\":5,\"airport\":6,\n","                           \"cheapest\":7,\"city\":8,\"distance\":9,\"flight\":10,\"flight_no\":11,\"flight_time\":12,\"flight+airfare\":13,\"meal\":14,\"quantity\":15}\n","        self.tokenizer = tokenizer\n","\n","     # 定義回傳一筆訓練 / 測試數據的函式\n","    def __getitem__(self , index):\n","            \n","        text, intent = self.df.iloc[index, :].values\n","        # 將 label 文字也轉換成索引方便轉換成 tensor\n","        intent_id = self.intent_map[intent]\n","        intent_tensor = torch.tensor(intent_id)\n","        \n","        \n","        \n","        word_pieces = [\"[CLS]\"]\n","        tokens = self.tokenizer.tokenize(text)\n","        word_pieces += tokens \n","        length = len(word_pieces)\n","\n","        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n","        segments_tensor = torch.tensor([0] * length, \n","                                        dtype=torch.long)\n","        \n","        # 將整個 token 序列轉換成索引序列\n","        indexs = self.tokenizer.convert_tokens_to_ids(word_pieces)\n","        tokens_tensor = torch.tensor(indexs)\n","\n","        return(tokens_tensor,segments_tensor,intent_tensor)\n","      \n","    def __len__(self):\n","        return self.len\n","        \n","# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n","trainset = ATIS_zh_Dataset(\"train\", tokenizer=tokenizer)\n","\n","\n","print(trainset[0])\n","# print(trainset[0][2])\n","\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(tensor([ 101,  784, 7938, 5661, 4408, 6536, 6244, 4825, 2179, 7269, 3532, 5661,\n","        4958, 2537, 1139, 4634, 1168, 6205, 7414, 1756, 1399, 1367, 2238]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor(12))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jUH2zc-Fgmo4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"ok","timestamp":1595927800485,"user_tz":-480,"elapsed":15003,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"d00bacda-2811-4575-d1c2-1c7188400b64"},"source":["# 選擇第一個樣本\n","sample_idx = 0\n","\n","# 將原始文本拿出做比較\n","text, intent = trainset.df.iloc[sample_idx].values\n","\n","# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n","tokens_tensor, segments_tensor, intent_tensor = trainset[sample_idx]\n","\n","# 將 tokens_tensor 還原成文本\n","tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n","combined_text = \"\".join(tokens)\n","\n","# 渲染前後差異\n","print(f\"\"\"[原始文本]\n","句子 1：{text}\n","分類  ：{intent}\n","\n","--------------------\n","\n","[Dataset 回傳的 tensors]\n","tokens_tensor  ：{tokens_tensor}\n","\n","segments_tensor：{segments_tensor}\n","\n","label_tensor   ：{intent_tensor}\n","\n","--------------------\n","\n","[還原 tokens_tensors]\n","{combined_text}\n","\"\"\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[原始文本]\n","句子 1：什麼航班資訊確實長榮航空從出發到西雅圖 名古屋\n","分類  ：flight_time\n","\n","--------------------\n","\n","[Dataset 回傳的 tensors]\n","tokens_tensor  ：tensor([ 101,  784, 7938, 5661, 4408, 6536, 6244, 4825, 2179, 7269, 3532, 5661,\n","        4958, 2537, 1139, 4634, 1168, 6205, 7414, 1756, 1399, 1367, 2238])\n","\n","segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","\n","label_tensor   ：12\n","\n","--------------------\n","\n","[還原 tokens_tensors]\n","[CLS]什麼航班資訊確實長榮航空從出發到西雅圖名古屋\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4r1lMoofxTqT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595927800486,"user_tz":-480,"elapsed":14995,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}}},"source":["\"\"\"\n","實作可以一次回傳一個 mini-batch 的 DataLoader\n","這個 DataLoader 吃我們上面定義的 `ATIS_zh_Dataset`，\n","回傳訓練 BERT 時會需要的 4 個 tensors：\n","- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n","- segments_tensors: (batch_size, max_seq_len_in_batch)\n","- masks_tensors   : (batch_size, max_seq_len_in_batch)\n","- label_ids       : (batch_size)\n","\"\"\"\n","\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n","# 剛剛定義的 `ATIS_zh_Dataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n","# - tokens_tensor\n","# - segments_tensor\n","# - label_tensor\n","# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n","\n","def create_mini_batch(samples):\n","    tokens_tensors = [s[0] for s in samples]\n","    segments_tensors = [s[1] for s in samples]\n","    \n","    # 測試集有 labels\n","\n","    label_ids = torch.stack([s[2] for s in samples])\n","    \n","    # zero pad 到同一序列長度\n","    tokens_tensors = pad_sequence(tokens_tensors, \n","                                  batch_first=True)\n","    segments_tensors = pad_sequence(segments_tensors, \n","                                    batch_first=True)\n","    \n","    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n","    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n","    masks_tensors = torch.zeros(tokens_tensors.shape, \n","                                dtype=torch.long)\n","    masks_tensors = masks_tensors.masked_fill(\n","        tokens_tensors != 0, 1)\n","    \n","    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n","\n","# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n","# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n","BATCH_SIZE = 64\n","trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n","                         collate_fn=create_mini_batch)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKK-O5S_W-ot","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"status":"ok","timestamp":1595927800488,"user_tz":-480,"elapsed":14987,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"81d70e0d-9e89-4400-948c-52cd930bc17c"},"source":["data = next(iter(trainloader)) \n","\n","tokens_tensors, segments_tensors, masks_tensors, label_ids = data\n","\n","print(f\"\"\"\n","tokens_tensors.shape   = {tokens_tensors.shape} \n","{tokens_tensors}\n","------------------------\n","segments_tensors.shape = {segments_tensors.shape}\n","{segments_tensors}\n","------------------------\n","masks_tensors.shape    = {masks_tensors.shape}\n","{masks_tensors}\n","------------------------\n","label_ids.shape        = {label_ids.shape}\n","{label_ids}\n","\"\"\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["\n","tokens_tensors.shape   = torch.Size([64, 38]) \n","tensor([[ 101,  784, 7938,  ...,    0,    0,    0],\n","        [ 101,  784, 7938,  ...,    0,    0,    0],\n","        [ 101, 6366, 2769,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 6205, 7414,  ...,    0,    0,    0],\n","        [ 101,  784, 7938,  ...,    0,    0,    0],\n","        [ 101,  784, 7938,  ...,    0,    0,    0]])\n","------------------------\n","segments_tensors.shape = torch.Size([64, 38])\n","tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]])\n","------------------------\n","masks_tensors.shape    = torch.Size([64, 38])\n","tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])\n","------------------------\n","label_ids.shape        = torch.Size([64])\n","tensor([12,  2,  2,  2,  2,  2,  2, 13,  4,  4,  2,  2,  2,  2,  4,  2,  2,  2,\n","        15,  2,  2,  4,  0,  2,  2,  4, 12,  2,  2, 15, 13,  2,  2,  5,  4,  0,\n","         2,  2,  2,  2, 12, 12,  2,  2,  4,  0,  4,  2, 15,  2,  2,  2,  2,  2,\n","         2, 12, 13,  2,  2,  2,  4,  4,  2,  2])\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rZn-XDX1LMf5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1595927805916,"user_tz":-480,"elapsed":20405,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"b228d9eb-b344-4ae1-c02a-5474f9c02189"},"source":["from transformers import BertForSequenceClassification\n","\n","#PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n","NUM_LABELS = 16 \n","\n","model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME,\n","                                                      num_labels=NUM_LABELS)\n","\n","print(\"\"\"\n","name            module\n","----------------------\"\"\")\n","for name, module in model.named_children():\n","    if name == \"bert\":\n","        for n, _ in module.named_children():\n","            print(f\"{name}:{n}\")\n","    else:\n","        print(\"{:15} {}\".format(name, module))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at hfl/chinese-bert-wwm were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-bert-wwm and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","name            module\n","----------------------\n","bert:embeddings\n","bert:encoder\n","bert:pooler\n","dropout         Dropout(p=0.1, inplace=False)\n","classifier      Linear(in_features=768, out_features=16, bias=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wvHfV8fmNhxy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1595927812117,"user_tz":-480,"elapsed":26597,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"3abf7741-9f24-45fd-896a-52deb0ebeea4"},"source":["\"\"\" (以下程式碼未更改)\n","定義一個可以針對特定 DataLoader 取得模型預測結果以及分類準確度的函式\n","之後也可以用來生成上傳到 Kaggle 競賽的預測結果\n","\n","2019/11/22 更新：在將 `tokens`、`segments_tensors` 等 tensors\n","丟入模型時，強力建議指定每個 tensor 對應的參數名稱，以避免 HuggingFace\n","更新 repo 程式碼並改變參數順序時影響到我們的結果。\n","\"\"\"\n","\n","def get_predictions(model, dataloader, compute_acc=False):\n","    predictions = None\n","    correct = 0\n","    total = 0\n","      \n","    with torch.no_grad(): #關掉反反向求導，參考:https://blog.csdn.net/songyu0120/article/details/103884586\n","        # 遍巡整個資料集\n","        for data in dataloader:\n","            # 將所有 tensors 移到 GPU 上\n","            if next(model.parameters()).is_cuda:\n","                data = [t.to(\"cuda:0\") for t in data if t is not None]\n","            \n","            \n","            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n","            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n","            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n","            outputs = model(input_ids=tokens_tensors, \n","                            token_type_ids=segments_tensors, \n","                            attention_mask=masks_tensors)\n","            \n","            logits = outputs[0]\n","            _, pred = torch.max(logits.data, 1)\n","            \n","            # 用來計算訓練集的分類準確率\n","            if compute_acc:\n","                labels = data[3]\n","                total += labels.size(0)\n","                correct += (pred == labels).sum().item()\n","                \n","            # 將當前 batch 記錄下來\n","            if predictions is None:\n","                predictions = pred\n","            else:\n","                predictions = torch.cat((predictions, pred))\n","    \n","    if compute_acc:\n","        acc = correct / total\n","        return predictions, acc\n","    return predictions\n","    \n","# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)\n","model = model.to(device)\n","_, acc = get_predictions(model, trainloader, compute_acc=True)\n","print(\"classification acc:\", acc)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["device: cuda:0\n","classification acc: 0.017830609212481426\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F9QLV7dpOQXs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1595927812118,"user_tz":-480,"elapsed":26589,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"b1ca49ab-c90d-401f-dbd2-d92e6d3c4f9a"},"source":["\"\"\"(以下程式碼未更改，非重點)\"\"\"\n","def get_learnable_params(module):\n","    return [p for p in module.parameters() if p.requires_grad]\n","     \n","model_params = get_learnable_params(model)\n","clf_params = get_learnable_params(model.classifier)\n","\n","print(f\"\"\"\n","整個分類模型的參數量：{sum(p.numel() for p in model_params)}\n","線性分類器的參數量：{sum(p.numel() for p in clf_params)}\n","\"\"\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","整個分類模型的參數量：102279952\n","線性分類器的參數量：12304\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BxZIBKbXOyVA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":151},"executionInfo":{"status":"ok","timestamp":1595927883020,"user_tz":-480,"elapsed":97482,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"38e8a7ed-8aa7-46af-ae20-378f5b21601e"},"source":["%%time\n","\n","# 訓練模式\n","model.train()\n","\n","# 使用 Adam Optim 更新整個分類模型的參數\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","\n","\n","EPOCHS = 6  # 訓練次數  -----------------------------------------------------------------------------------\n","for epoch in range(EPOCHS):\n","    \n","    running_loss = 0.0\n","    for data in trainloader:\n","        \n","        tokens_tensors, segments_tensors, \\\n","        masks_tensors, labels = [t.to(device) for t in data]\n","\n","        # 將參數梯度歸零\n","        optimizer.zero_grad()\n","        \n","        # forward pass\n","        outputs = model(input_ids=tokens_tensors, \n","                        token_type_ids=segments_tensors, \n","                        attention_mask=masks_tensors, \n","                        labels=labels)\n","\n","        loss = outputs[0]\n","        # backward\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","        # 紀錄當前 batch loss\n","        running_loss += loss.item()\n","        \n","    # 計算分類準確率\n","    _, acc = get_predictions(model, trainloader, compute_acc=True)\n","\n","    print('[epoch %d] loss: %.3f, acc: %.3f' %\n","          (epoch + 1, running_loss, acc))\n","    "],"execution_count":18,"outputs":[{"output_type":"stream","text":["[epoch 1] loss: 24.408, acc: 0.574\n","[epoch 2] loss: 17.452, acc: 0.670\n","[epoch 3] loss: 14.554, acc: 0.733\n","[epoch 4] loss: 12.240, acc: 0.788\n","[epoch 5] loss: 10.144, acc: 0.811\n","[epoch 6] loss: 8.753, acc: 0.831\n","CPU times: user 45.2 s, sys: 25.8 s, total: 1min 10s\n","Wall time: 1min 11s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8BlWu4COoYeU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1595927886477,"user_tz":-480,"elapsed":100927,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"74cb3e52-aa57-4c1f-9550-fd5dfd894ed0"},"source":["%%time \n","# 關注這個準確率!!!(越高越好)\n","# 建立測試集。這邊我們可以用跟訓練時不同的 batch_size，看你 GPU 多大\n","testset = ATIS_zh_Dataset(\"train\" , tokenizer=tokenizer)\n","\n","testloader = DataLoader(testset, batch_size=16, \n","                        collate_fn=create_mini_batch)\n","\n","# 用分類模型預測測試集\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)\n","model = model.to(device)\n","_, acc = get_predictions(model, testloader, compute_acc=True)\n","print(\"TestDataset classification acc:\", acc)\n","\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["device: cuda:0\n","TestDataset classification acc: 0.826151560178306\n","CPU times: user 2.41 s, sys: 1.02 s, total: 3.43 s\n","Wall time: 3.44 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GqN3R6842G4m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1595927886478,"user_tz":-480,"elapsed":100915,"user":{"displayName":"邱承漢","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDSPO-54pnv1Wr-eAeQnwgmFxEtL5a9giLiAPqcQ=s64","userId":"15147061623686384475"}},"outputId":"aaa4ee59-4cb8-401a-8c72-be25bb1156eb"},"source":["intput_sentence =\"什麼航空公司有從西雅圖到名古屋 轉機 早上的 早上的航班\t\"\n","inputs = tokenizer.encode_plus(intput_sentence, return_tensors='pt', add_special_tokens=True)\n","print(inputs)\n","\n","input_ids = inputs['input_ids']\n","token_type_ids = inputs['token_type_ids']\n","attention_mask = inputs['attention_mask']\n","print(\"--------------------------------------------\")\n","input_ids = input_ids.to(device)\n","token_type_ids = token_type_ids.to(device)\n","attention_mask = attention_mask.to(device)\n","model = model.to(device)\n","\n","outputs = model(input_ids=input_ids, \n","                token_type_ids=token_type_ids, \n","                attention_mask=attention_mask,labels=None)\n","logits = outputs[0] # 記得一定要指定[0]!!\n","#print(outputs)\n","print(logits) #這兩個不知道為啥一樣\n","_,pred = torch.max(logits.data, 1)\n","print(pred)\n","intent_dic = {0:\"aircraft\",1:\"aircraft+flight+flight_no\",2:\"airfare\",3:\"airfare+flight_time\",4:\"airline\",5:\"airline+flight_no\",6:\"airport\",\n","                           7:\"cheapest\",8:\"city\",9:\"distance\",10:\"flight\",11:\"flight_no\",12:\"flight_time\",13:\"flight+airfare\",14:\"meal\",15:\"quantity\"}\n","\n","print(\"intent:\" ,intent_dic[pred.item()])\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["{'input_ids': tensor([[ 101,  784, 7938, 5661, 4958, 1062, 1385, 3300, 2537, 6205, 7414, 1756,\n","         1168, 1399, 1367, 2238, 6752, 3582, 3193,  677, 4638, 3193,  677, 4638,\n","         5661, 4408,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1]])}\n","--------------------------------------------\n","tensor([[-0.0733, -0.4989, -0.2039, -1.2736,  3.5240, -0.3758, -0.3227, -0.5499,\n","         -0.8681, -0.2167,  0.4653, -0.8231,  0.6971,  0.0504, -0.5150, -0.0999]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)\n","tensor([4], device='cuda:0')\n","intent: airline\n"],"name":"stdout"}]}]}